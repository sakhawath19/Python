MISSING VALUE 
-----------------------------------------------------------------------------------------------------------------------------
-k-Nearest Neighbors that can ignore a column from a distance measure when a value is missing. 
Naive Bayes can also support missing values when making a prediction.

IMPUTE MISSING VALUE

-A constant value that has meaning within the domain, such as 0, distinct from all other values.
-A value from another randomly selected record.
-A mean, median or mode value for the column.
-A value estimated by another predictive model.

-Any imputing performed on the training dataset will have to be performed on new data in the 
future when predictions are needed from the finalized model. This needs to be taken into 
consideration when choosing how to impute the missing values. For example, if you choose 
to impute with mean column values, these mean column values will need to be stored to file 
for later use on new data that has missing values.



PREPARE DATA
-----------------------------------------------------------------------------------------------------------------------------

Generally, I would recommend creating many dierent views and transforms of your data,
then exercise a handful of algorithms on each view of your dataset. This will help you to 
fush out which data transforms might be better at exposing the structure of your problem in general.


- RESCALE DATA

useful for algorithms that weight inputs like regression and neural networks and algorithms that 
use distance measures like k-Nearest Neighbors.


- STANDARDIZE

It is most suitable for techniques that assume a Gaussian distribution in the input variables and 
work better with rescaled data, such as linear regression, logistic regression and linear discriminate analysis.


- NORMALIZE

This pre-processing method can be useful for sparse datasets (lots of zeros) with attributes of varying 
scales when using algorithms that weight input values such as neural networks and algorithms that use
distance measures such as k-Nearest Neighbors.


- BINARIZE 

It can be useful when you have probabilities that you want to make into crisp values. It is also useful 
when feature engineering and you want to add new features that indicate something meaningful.


